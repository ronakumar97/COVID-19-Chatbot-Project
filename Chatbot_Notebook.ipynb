{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ACpHo1FAKPdA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 11:35:24.912678: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-20 11:35:24.912709: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bKxOC0XkSa_r"
   },
   "outputs": [],
   "source": [
    "# Loading the spaCy module \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kzIAIPTMKRQ0"
   },
   "outputs": [],
   "source": [
    "# Opening the intents.json file \n",
    "\n",
    "with open('intents.json') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y6QCeBqJKoD1"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the intents to remove unwanted characters\n",
    "\n",
    "def preprocessing(line):\n",
    "    line = re.sub(r'[^a-zA-z.?!\\']', ' ', line)\n",
    "    line = re.sub(r'[ ]+', ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "geO92q-sLD1k"
   },
   "outputs": [],
   "source": [
    "# Running the above method and creating inputs, targets from the intents.json file\n",
    "\n",
    "inputs, targets = [], []\n",
    "classes = []\n",
    "intent_doc = {}\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    if intent['intent'] not in classes:\n",
    "        classes.append(intent['intent'])\n",
    "    if intent['intent'] not in intent_doc:\n",
    "        intent_doc[intent['intent']] = []\n",
    "        \n",
    "    for text in intent['text']:\n",
    "        inputs.append(preprocessing(text))\n",
    "        targets.append(intent['intent'])\n",
    "        \n",
    "    for response in intent['responses']:\n",
    "        intent_doc[intent['intent']].append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jmNBZJUgLFAT"
   },
   "outputs": [],
   "source": [
    "# Tokenizing the inputs using keras and padding them to generate equal length sequences\n",
    "\n",
    "def tokenize_data(input_list):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n",
    "    \n",
    "    tokenizer.fit_on_texts(input_list)\n",
    "    \n",
    "    input_seq = tokenizer.texts_to_sequences(input_list)\n",
    "\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, padding='pre')\n",
    "    \n",
    "    return tokenizer, input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the above function with the inputs\n",
    "\n",
    "tokenizer, input_tensor = tokenize_data(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_R9KdPLCLGVj"
   },
   "outputs": [],
   "source": [
    "# Creating the categorical tensor for the target variables\n",
    "\n",
    "def create_categorical_target(targets):\n",
    "    word={}\n",
    "    categorical_target=[]\n",
    "    counter=0\n",
    "    for trg in targets:\n",
    "        if trg not in word:\n",
    "            word[trg]=counter\n",
    "            counter+=1\n",
    "        categorical_target.append(word[trg])\n",
    "    \n",
    "    categorical_tensor = tf.keras.utils.to_categorical(categorical_target, num_classes=len(word), dtype='int32')\n",
    "    return categorical_tensor, dict((v,k) for k, v in word.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the above function with the targets\n",
    "\n",
    "target_tensor, trg_index_word = create_categorical_target(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "igJV6DkwLJVj"
   },
   "outputs": [],
   "source": [
    "# Setting up the variables for the LSTM network\n",
    "\n",
    "epochs=50\n",
    "vocab_size=len(tokenizer.word_index) + 1\n",
    "embed_dim=512\n",
    "units=128\n",
    "target_length=target_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HL7_RRC-LKzD",
    "outputId": "bad2ead4-7e93-4f08-d691-ba00a5652997"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 11:35:27.825678: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-04-20 11:35:27.825727: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pop-os\n",
      "2022-04-20 11:35:27.825740: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pop-os\n",
      "2022-04-20 11:35:27.825924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.86.0\n",
      "2022-04-20 11:35:27.825964: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.86.0\n",
      "2022-04-20 11:35:27.825977: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.86.0\n",
      "2022-04-20 11:35:27.826462: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 512)         75264     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              656384    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 765,189\n",
      "Trainable params: 765,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronak/PycharmProjects/Chatbot/venv/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# LSTM Sequential model for prediction\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, dropout=0.2)),\n",
    "    tf.keras.layers.Dense(units, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(target_length, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-2)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHaC86omLMUT",
    "outputId": "c6be900a-8cda-4c88-f1fe-e017d250fc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 4s 22ms/step - loss: 1.6049 - accuracy: 0.2394\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.2747 - accuracy: 0.4789\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4836 - accuracy: 0.7746\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3241 - accuracy: 0.8310\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1932 - accuracy: 0.9014\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1702 - accuracy: 0.9014\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1110 - accuracy: 0.9577\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0760 - accuracy: 0.9859\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 4.3186e-04 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 9.2452e-05 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.3803e-04 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2.7623e-04 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0078e-05 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2.4685e-05 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 7.1385e-05 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1276 - accuracy: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2903acdf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the EarlyStop callback to finish training once accuracy doesn't improve further\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(input_tensor, target_tensor, epochs=epochs, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0sGvuA5LOn0",
    "outputId": "5b40f2ce-8516-4d6b-d34e-1f27bb85dd09"
   },
   "outputs": [],
   "source": [
    "# Getting the response from the model for an input sentence\n",
    "\n",
    "def response(sentence):\n",
    "    sent_seq = []\n",
    "    doc = nlp(repr(sentence))\n",
    "    \n",
    "    # split the input sentences into words\n",
    "    for token in doc:\n",
    "        if token.text in tokenizer.word_index:\n",
    "            sent_seq.append(tokenizer.word_index[token.text])\n",
    "\n",
    "        # handle the unknown words error\n",
    "        else:\n",
    "            sent_seq.append(tokenizer.word_index['<unk>'])\n",
    "\n",
    "    sent_seq = tf.expand_dims(sent_seq, 0)\n",
    "    pred = model(sent_seq)\n",
    "\n",
    "    pred_class = np.argmax(pred.numpy(), axis=1)\n",
    "    \n",
    "    return random.choice(intent_doc[trg_index_word[pred_class[0]]]), trg_index_word[pred_class[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome. I am your COVID-19 bot. How can I help ?\n",
      "You: Hello. Is anyone here ?\n",
      "INTENT TYPE -> Greeting\n",
      "RESPONSE -> Hello thanks for visiting. How can I help you?\n",
      "\n",
      "You: What is coronavirus ?\n",
      "INTENT TYPE -> Information\n",
      "RESPONSE -> Coronavirus disease 2019 (COVID-19) is a contagious disease caused by a virus, the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The first known case was identified in Wuhan, China, in December 2019. The disease has since spread worldwide, leading to the ongoing COVID-19 pandemic\n",
      "\n",
      "You: What precautions I have to take ?\n",
      "INTENT TYPE -> Precautions\n",
      "RESPONSE -> To prevent the spread of COVID-19: Maintain a safe distance from others (at least 1 metre), even if they don’t appear to be sick. Wear a mask in public, especially indoors or when physical distancing is not possible. Choose open, well-ventilated spaces over closed ones. Open a window if indoors. Clean your hands often. Use soap and water, or an alcohol-based hand rub. Get vaccinated when it’s your turn. Follow local guidance about vaccination. Cover your nose and mouth with your bent elbow or a tissue when you cough or sneeze. Stay home if you feel unwell.\n",
      "\n",
      "You: Can I use public transportation ?\n",
      "INTENT TYPE -> Transport\n",
      "RESPONSE -> To protect everyone who rides, stay at home if you're sick. Don't ride public transportation if you have symptoms or you know you've been around someone with COVID-19 and it is recommended that you quarantine. It's possible to spread the virus once you're infected, even if you don't show symptoms. Travel at off-peak times when you can -- like late morning or before evening rush hour. Avoid subway cars and buses packed with people. If you count more than 10-15 passengers on your bus or train, wait for the next one. Leave an empty seat between you and the next passenger\n",
      "\n",
      "You: That's helpful\n",
      "INTENT TYPE -> Thanks\n",
      "RESPONSE -> Happy to help\n",
      "\n",
      "You: q\n",
      "Thanks for using COVID-19 bot. Goodbye :)\n"
     ]
    }
   ],
   "source": [
    "# Interacting with the bot\n",
    "print(\"Welcome. I am your COVID-19 bot. How can I help ?\")\n",
    "\n",
    "while True:\n",
    "    input_ = input('You: ')\n",
    "    if input_.lower() == 'q':\n",
    "        print(\"Thanks for using COVID-19 bot. Goodbye :)\")\n",
    "        break\n",
    "    \n",
    "    result, type = response(input_)\n",
    "        \n",
    "    print('INTENT TYPE -> {}'.format(type))\n",
    "    print('RESPONSE -> {}'.format(result))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
